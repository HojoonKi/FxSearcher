---
---

<!DOCTYPE html>
<html lang="en-US">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>FxSearcher: Algorithm based CLAP-supervised FX searching agent</title>
    <style>
        /* 기본 스타일 */
        body {
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif;
            margin: 0;
            padding: 0;
            background-color: #f5f5f7;
            color: #1d1d1f;
        }
        /* 메인 컨테이너 */
        .container {
            max-width: 800px;
            margin: 40px auto;
            padding: 20px 40px;
            background-color: #ffffff;
            border-radius: 12px;
            box-shadow: 0 4px 12px rgba(0,0,0,0.05);
        }
        /* 제목 */
        h1, h2 {
            border-bottom: 1px solid #e5e5e5;
            padding-bottom: 10px;
        }
        h1 {
            font-size: 2.5em;
            text-align: center;
        }
        h2 {
            font-size: 1.8em;
            color: #0071e3;
        }
        p {
            line-height: 1.6;
            text-align: justify;
        }
        /* 각 예시 섹션 */
        .example {
            margin-bottom: 40px;
        }
        /* 오디오 플레이어 레이아웃 */
        .audio-players {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
            gap: 20px;
            margin-top: 20px;
        }
        .audio-player p {
            margin: 0 0 8px 0;
            font-weight: 600;
        }
        /* 오디오 태그 스타일 */
        audio {
            width: 100%;
        }
        /* 링크 스타일 */
        a {
            color: #0071e3;
            text-decoration: none;
        }
        a:hover {
            text-decoration: underline;
        }
        /* Table Styles */
        table {
            width: 100%;
            border-collapse: collapse;
            margin-top: 30px;
            font-size: 0.9em;
        }
        th, td {
            border: 1px solid #e5e5e5;
            padding: 12px;
            text-align: left;
            vertical-align: middle;
        }
        thead {
            background-color: #f5f5f7;
        }
        th {
            font-weight: 600;
        }
        tbody tr:nth-child(even) {
            background-color: #f5f5f7;
        }
        td audio {
            max-width: 200px;
            height: 40px;
        }
    </style>
    <script>
    window.MathJax = {
      tex: {
        inlineMath: [['\\(', '\\)']] // 인라인 수식은 \(...\) 기호를 사용한다고 명시
      }
    };
    </script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>
<body>

    <div class="container">
        <header>
            <h1>Automatic Audio FX Search Results</h1>
            <p>
                This page demonstrates the results of an automatic audio FX parameter searching agent, Fxsearcher. The system takes a source audio file and a text prompt, then uses the CLAP model and Bayesian Optimization to find the optimal effects chain and parameters.
            </p>
        </header>

        <main>

            <div class="example">
                <h2>Benchmark Results</h2>
                <p>
                    Comparative results between our FxSearch model and the Text2FX baseline. For Text2FX, Eq and Reverb was applied as FX chain for all examples.
                </p>
                <table>
                    <thead>
                        <tr>
                            <th>Target Prompt</th>
                            <th>FX Chain(FxSearcher)</th>
                            <th>Audio Type</th>
                            <th>Clean Audio</th>
                            <th>FxSearcher</th>
                            <th>Text2FX</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td>A ghostly child's voice echoing in a hallway</td>
                            <td>EQ, Reverb, PitchShift</td>
                            <td>Speech</td>
                            <td>
                                <audio controls src="{{ '/audio/A_ghostly_childs_voice_echoing_in_a_hallway/original.wav' | relative_url }}"></audio>
                            </td>
                            <td>
                                <audio controls src="{{ '/audio/A_ghostly_childs_voice_echoing_in_a_hallway/best.wav' | relative_url }}"></audio>
                            </td>
                            <td>
                                <audio controls src="{{ '/audio/A_ghostly_childs_voice_echoing_in_a_hallway/output.wav' | relative_url }}"></audio>
                            </td>
                        </tr>
                        <tr>
                            <td>A metallic robot's cold voice</td>
                            <td>EQ, Reverb, Delay, PitchShift</td>
                            <td>Speech</td>
                            <td><audio controls src="{{ '/audio/A_metallic_robots_cold_voice/original.wav' | relative_url }}"></audio></td>
                            <td><audio controls src="{{ '/audio/A_metallic_robots_cold_voice/best.wav' | relative_url }}"></audio></td>
                            <td><audio controls src="{{ '/audio/A_metallic_robots_cold_voice/output.wav' | relative_url }}"></audio></td>
                        </tr>
                        <tr>
                            <td>A monster speaking inside a cave</td>
                            <td>EQ, Reverb, Distortion, PitchShift, BitCrush</td>
                            <td>Instrumental</td>
                            <td><audio controls src="{{ '/audio/A_monster_speaking_inside_a_cave/original.wav' | relative_url }}"></audio></td>
                            <td><audio controls src="{{ '/audio/A_monster_speaking_inside_a_cave/best.wav' | relative_url }}"></audio></td>
                            <td><audio controls src="{{ '/audio/A_monster_speaking_inside_a_cave/output.wav' | relative_url }}"></audio></td>
                        </tr>
                        <tr>
                            <td>A powerful and destructive drum sound</td>
                            <td>EQ, Distortion, PitchShift</td>
                            <td>Speech</td>
                            <td><audio controls src="{{ '/audio/A_powerful_and_destructive_drum_sound/original.wav' | relative_url }}"></audio></td>
                            <td><audio controls src="{{ '/audio/A_powerful_and_destructive_drum_sound/best.wav' | relative_url }}"></audio></td>
                            <td><audio controls src="{{ '/audio/A_powerful_and_destructive_drum_sound/output.wav' | relative_url }}"></audio></td>
                        </tr>
                        <tr>
                            <td>An electric guitar played underwater</td>
                            <td>EQ, PitchShift, BitCrush</td>
                            <td>Instrumental</td>
                            <td><audio controls src="{{ '/audio/A_electric_guitar_played_underwater/original.wav' | relative_url }}"></audio></td>
                            <td><audio controls src="{{ '/audio/A_electric_guitar_played_underwater/best.wav' | relative_url }}"></audio></td>
                            <td><audio controls src="{{ '/audio/A_electric_guitar_played_underwater/output.wav' | relative_url }}"></audio></td>
                        </tr>
                        <tr>
                            <td>A saxophone buzzing like it's trapped in an old radio</td>
                            <td>EQ, Reverb, Delay, PitchShift, BitCrush</td>
                            <td>Instrumental</td>
                            <td><audio controls src="{{ '/audio/A_saxophone_buzzing_like_its_trapped_in_an_old_radio/original.wav' | relative_url }}"></audio></td>
                            <td><audio controls src="{{ '/audio/A_saxophone_buzzing_like_its_trapped_in_an_old_radio/best.wav' | relative_url }}"></audio></td>
                            <td><audio controls src="{{ '/audio/A_saxophone_buzzing_like_its_trapped_in_an_old_radio/output.wav' | relative_url }}"></audio></td>
                        </tr>
                        <tr>
                            <td>A preacher's booming voice in a vast cathedral</td>
                            <td>EQ, Reverb, Distortion, BitCrush</td>
                            <td>Speech</td>
                            <td><audio controls src="{{ '/audio/A_preachers_booming_voice_in_a_vast_cathedral/original.wav' | relative_url }}"></audio></td>
                            <td><audio controls src="{{ '/audio/A_preachers_booming_voice_in_a_vast_cathedral/best.wav' | relative_url }}"></audio></td>
                            <td><audio controls src="{{ '/audio/A_preachers_booming_voice_in_a_vast_cathedral/output.wav' | relative_url }}"></audio></td>
                        </tr>
                        <tr>
                            <td>A soldier shouting orders through a walkie-talkie</td>
                            <td>EQ, Reverb, Distortion</td>
                            <td>Speech</td>
                            <td><audio controls src="{{ '/audio/A_soldier_shouting_orders_through_a_walkie_talkie/original.wav' | relative_url }}"></audio></td>
                            <td><audio controls src="{{ '/audio/A_soldier_shouting_orders_through_a_walkie_talkie/best.wav' | relative_url }}"></audio></td>
                            <td><audio controls src="{{ '/audio/A_soldier_shouting_orders_through_a_walkie_talkie/output.wav' | relative_url }}"></audio></td>
                        </tr>
                        </tbody>
                </table>
                <div class="example">
                    <h2>How Bayesian Optimization Works</h2>
                    <p>
                        This project uses Bayesian Optimization to efficiently find the best effect parameters. Unlike grid search or random search, which are "blind," Bayesian Optimization intelligently decides which parameters to try next based on all previous results. It's designed to find the global optimum of expensive, black-box functions in as few steps as possible.
                    </p>
                    <p>
                        The process consists of two key components: a <strong>Surrogate Model</strong> and an <strong>Acquisition Function</strong>.
                    </p>

                    <h3>1. Surrogate Model (Gaussian Process)</h3>
                    <p>
                        We don't know the true, complex relationship \(f(x)\) between parameters \(x\) and the CLAP score. Bayesian Optimization builds a probabilistic model to approximate this relationship. This surrogate model, typically a <strong>Gaussian Process (GP)</strong>, creates a "map of possibilities" based on the points we've already evaluated.
                    </p>
                    <p>
                        A GP models the function as a multivariate normal distribution:
                        $$ f(x) \sim \mathcal{GP}(\mu(x), k(x, x')) $$
                        Here, \(\mu(x)\) is the mean function (our prior belief about the score), and \(k(x, x')\) is the kernel, or covariance function, which models the similarity between points. After observing data \(D_{1:t} = \{(x_1, y_1), \dots, (x_t, y_t)\}\), the GP is updated to a posterior distribution. This posterior gives us a prediction for any new point \(x\), providing both a predicted mean \(\mu_t(x)\) (the expected score) and a variance \(\sigma_t^2(x)\) (our uncertainty about that score).
                    </p>

                    <h3>2. Acquisition Function</h3>
                    <p>
                        The acquisition function guides the search by deciding which point \(x\) to evaluate next. It balances two competing goals:
                        <ul>
                            <li><strong>Exploitation:</strong> Choosing points where the surrogate model predicts a high score (low uncertainty, high mean).</li>
                            <li><strong>Exploration:</strong> Choosing points where the model is most uncertain (high variance), in hopes of discovering a new, unobserved peak.</li>
                        </ul>
                    </p>
                    <p>
                        A common acquisition function is <strong>Expected Improvement (EI)</strong>. It calculates the expected amount of improvement over the best score found so far, \(y^+ = \max(y_1, \dots, y_t)\). The formula is:
                        $$ \text{EI}(x) = (\mu_t(x) - y^+) \Phi(Z) + \sigma_t(x) \phi(Z) \quad \text{where} \quad Z = \frac{\mu_t(x) - y^+}{\sigma_t(x)} $$
                        Here, \(\Phi\) and \(\phi\) are the CDF and PDF of the standard normal distribution. This formula elegantly balances exploiting high-mean regions (the first term) and exploring high-variance regions (the second term).
                    </p>
                    <p>
                        This project uses the <strong>Lower Confidence Bound (LCB)</strong> acquisition function, which provides a more direct way to control this trade-off:
                        $$ \text{LCB}(x) = \mu_t(x) - \kappa \sigma_t(x) $$
                        By increasing the hyperparameter \(\kappa\), we can encourage the algorithm to be more 'adventurous' and prioritize exploration of uncertain regions. The next point to sample, \(x_{t+1}\), is the one that maximizes the acquisition function: \(x_{t+1} = \text{argmax}_{x} \text{EI}(x)\).
                    </p>
            </div>
            </div>
            
            </main>
    </div>

</body>
</html>